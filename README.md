# GPT-2-from-sctach
Making GPT-2 from scracth with modifications of ROPE, sliding window attention and grouped query attention<br>
The jupyter notebook contains all the description of all the tasks and the standalone files are also provided for reference<br>
The modified architecture was trained with a scontext size of 25 and still it outperformed the original GPT-2 architecture<br>
The dataset used for training is shakespeher.txt<br>
Hope you like it!
